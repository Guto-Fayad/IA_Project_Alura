{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAyQZKWiF4M3VXPPWQ16YZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guto-Fayad/IA_Project_Alura/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7ysfNtXxiUXx"
      },
      "outputs": [],
      "source": [
        "### aqui começa a aula 05\n",
        "## importando as libs\n",
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "##pegando a chave\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get( 'SECRET_KEY')\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# configurando variaveis\n",
        "generation_config = {\n",
        "    \"candidate_count\":1,\n",
        "    \"temperature\":0.5\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}\n",
        "\n",
        "## gerando o embedding\n",
        "title = \"The next generation of AI for developers and Google Workspace\"\n",
        "sample_text = (\"Title: The next generation of AI for developers and Google Workspace\"\n",
        "    \"\\n\"\n",
        "    \"Full article:\\n\"\n",
        "    \"\\n\"\n",
        "    \"Gemini API & Google AI Studio: An approachable way to explore and prototype with generative AI applications\")\n",
        "\n",
        "\n",
        "model = 'models/embedding-001'\n",
        "\n",
        "result_embedding = genai.embed_content(model=model,\n",
        "                                content=sample_text,\n",
        "                                task_type=\"RETRIEVAL_DOCUMENT\",\n",
        "                                title=title)\n",
        "\n",
        "# criando o conteudo de feed do modelo\n",
        "\n",
        "DOCUMENT1 = {\n",
        "    \"Area\": \"Zona da Lagoa\",\n",
        "    \"Locais\": \"Cidade Nova, da Avenida Portugal até a Lagoa; Cohab I e II, Buchholz a partir da Visconde de Mauá até a Lagoa); Miguel de Castro Moreira (a partir da Henrique Pancada); Rheingantz e Presidente Vargas até o Saco da Mangueira; Vila Prado.\"}\n",
        "DOCUMENT2 = {\n",
        "    \"Area\": \"Zona Central\",\n",
        "    \"Locais\": \"Centro Histórico; Lar Gaúcho (por totalidade); Navegantes (por totalidade); BGV; Duas quadras no entorno do Canalete para sul e para norte (Major Carlos Pinto); Barroso até a Benjamin Constant; Coronel Sampaio; Francisco Marques.\"}\n",
        "DOCUMENT3 = {\n",
        "    \"Area\": \"Zona Avenida Itália\",\n",
        "    \"Locais\": \"Do Trevo até Bernardeth.\"}\n",
        "DOCUMENT4 = {\n",
        "    \"Area\": \"Zona Oeste Orla\",\n",
        "    \"Locais\": \"São Miguel e São João; Bernardo Taveira até a Lagoa; Recreio e Profilurb; Barão de Santo ngelo até a Lagoa; Vila Maria dos Anjos\"}\n",
        "DOCUMENT5 = {\n",
        "    \"Area\": \"Zona Porto Novo\",\n",
        "    \"Locais\": \"Vila Militar; Santa Tereza (por totalidade); BGV\"}\n",
        "DOCUMENT6 = {\n",
        "    \"Area\": \"Zona Portuária Industrial (Distrito Industrial)\",\n",
        "    \"Locais\": \"Barra (nova e velha - por totalidade) e Mangueira (por totalidade)\"}\n",
        "\n",
        "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3, DOCUMENT4, DOCUMENT5, DOCUMENT6]\n",
        "\n",
        "\n",
        "# montando no formato de tabela (embedding)\n",
        "df = pd.DataFrame(documents)\n",
        "df.columns = [\"Area\", \"Locais\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## criando a função para montar embedding\n",
        "def embed_fn(Area,Locais):\n",
        "  model = 'models/embedding-001'\n",
        "  result_embedding = genai.embed_content(model=model,\n",
        "                                content=Locais,\n",
        "                                task_type=\"RETRIEVAL_DOCUMENT\",\n",
        "                                title=Area)[\"embedding\"]\n",
        "  return result_embedding"
      ],
      "metadata": {
        "id": "Z09L35e5iY_i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Embeddings\"] = df.apply(lambda row: embed_fn(row[\"Area\"],row[\"Locais\"]),axis=1)"
      ],
      "metadata": {
        "id": "47hihkWJidLX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## função para buscar o conteudo  de uma consulta no tabela embedding\n",
        "def gerar_buscar_consulta (consulta,base,model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model,\n",
        "                                content=consulta,\n",
        "                                task_type=\"RETRIEVAL_QUERY\") [\"embedding\"]\n",
        "  produto_escalares = np.dot(np.stack(df[\"Embeddings\"]),embedding_da_consulta)\n",
        "  maior_similaridade = np.argmax(produto_escalares)\n",
        "\n",
        "  if maior_similaridade >= 3:\n",
        "    return \"Consulta relevante. Similaridade máxima: {}\".format(maior_similaridade)\n",
        "  else:\n",
        "    return \"Consulta indevida. Baixa relação semântica com a base de dados. Similaridade máxima: {}\".format(maior_similaridade)"
      ],
      "metadata": {
        "id": "nd0Sy2tNifeP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consulta =input(\"Informe o nome do seu Bairro :\")\n",
        "while consulta !=\"fim\":\n",
        "  Locais_atingidos = gerar_buscar_consulta(consulta,df,model)\n",
        "  print(Locais_atingidos)\n",
        "  prompt =input(\"Informe o nome do seu Bairro :\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "RlAPddW9ikIQ",
        "outputId": "689c2e14-fa9d-46db-e743-75af030e707b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recreio\n",
            "Consulta indevida. Baixa relação semântica com a base de dados. Similaridade máxima: 2\n",
            "chevete\n",
            "Consulta indevida. Baixa relação semântica com a base de dados. Similaridade máxima: 2\n",
            "sao miguel\n",
            "Consulta indevida. Baixa relação semântica com a base de dados. Similaridade máxima: 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1e699cc691f3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mLocais_atingidos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgerar_buscar_consulta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsulta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLocais_atingidos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Locais_atingidos = gerar_buscar_consulta(\"autorização\",df,model)\n",
        "print(Locais_atingidos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mvh0BS_YjUco",
        "outputId": "528653c6-2c6c-4cf3-c96d-41ce2001d33c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consulta relevante. Similaridade máxima: 5\n"
          ]
        }
      ]
    }
  ]
}